```cpp
/**
 * include/detector.h
 * FaceDetector class
 * @version 1.0 2026-01-03
 * @author cacc
 */
#ifndef DETECTOR_H
#define DETECTOR_H

#include <iostream>
#include <vector>
#include <string>
#include <opencv2/opencv.hpp>
#include <torch/script.h>

struct DetectionBox {
    cv::Rect bbox;
    float score;
};

class Detector {
public:
    explicit Detector(const std::string& model_path);
    std::vector<DetectionBox> inference(cv::Mat& frame);

private:
    torch::jit::script::Module module;
    torch::Device device = torch::kCUDA;
};
#endif
```

```cpp
/**
 * include/tracker.h
 * @version 1.0 2026-01-03
 * @author cacc
 */
#ifndef TRACKER_H
#define TRACKER_H

#include <opencv2/opencv.hpp>
#include "detector.h"

struct SharedTrack {
    cv::Rect bbox;
    float score;
    int track_id;
    int frames_since_update;
    cv::KalmanFilter kalman;

    SharedTrack(DetectionBox detection_box, int id);
    void predict();
    void update(DetectionBox detection_box);
};

class SortTracker {
public:
    SortTracker(int max_age = 30, float iou_threshold = 0.3);
    std::vector<SharedTrack> update(const std::vector<DetectionBox>& detections);

private:
    int next_id = 1;
    int max_age;
    float iou_threshold;
    std::vector<SharedTrack> tracks;

    double get_iou(cv::Rect rect1, cv::Rect rect2);
};

#endif //TRACKER_H
```

```cpp
/**
 * src/face_detector.cpp
 * @version 1.0 2026-01-03
 * @author cacc
 */
#include "detector.h"
#include <fstream>
#include <torch/cuda.h>

Detector::Detector(const std::string &model_path) {
    try {
        if (torch::cuda::is_available()) {
            std::cout << "CUDA is available! Using GPU: " << torch::cuda::device_count() << std::endl;
            device = torch::kCUDA;
        } else {
            std::cout << "CUDA not found! Using CPU." << std::endl;
            device = torch::kCPU;
        }

        std::ifstream is(model_path, std::ios::binary);
        if (!is) throw std::runtime_error("Cannot open model file: " + model_path);

        module = torch::jit::load(is, device);
        module.eval();

        // Warmup (Crucial for GPU initialization)
        torch::NoGradGuard no_grad;
        auto warmup_input = torch::zeros({1, 3, 640, 640}).to(device);
        module.forward({warmup_input});

        std::cout << "Model loaded and warmed up on " << (device.is_cuda() ? "GPU" : "CPU") << std::endl;
    } catch (const std::exception &e) {
        std::cerr << "Initialization failed: " << e.what() << std::endl;
        exit(-1);
    }
}

std::vector<DetectionBox> Detector::inference(cv::Mat &frame) {
    if (frame.empty()) return {};

    // 1. Pre-processing (CPU)
    cv::Mat resized;
    cv::resize(frame, resized, cv::Size(640, 640));
    cv::cvtColor(resized, resized, cv::COLOR_BGR2RGB);

    // 2. Data Upload to GPU
    // .clone() is mandatory to ensure the Mat memory isn't corrupted during async GPU tasks
    torch::Tensor input_tensor = torch::from_blob(resized.data, {1, 640, 640, 3}, torch::kByte).clone();
    input_tensor = input_tensor.permute({0, 3, 1, 2}).to(device).to(torch::kFloat).div(255.0);

    // 3. GPU Inference
    torch::NoGradGuard no_grad;
    torch::Tensor output;
    try {
        output = module.forward({input_tensor}).toTensor();
    } catch (const std::exception &e) {
        std::cerr << "Forward Error: " << e.what() << std::endl;
        return {};
    }

    // 4. Move to CPU and Sync
    // Crossing from GPU to CPU is where 0xC0000005 usually happens.
    // We move the tensor back to CPU before touching its internal pointers.
    output = output.to(torch::kCPU).squeeze().detach();

    if (output.dim() < 2) return {};

    // Handle YOLOv8 shape [84, 8400] -> [8400, 84]
    if (output.size(0) < output.size(1)) {
        output = output.transpose(0, 1);
    }
    output = output.contiguous(); // Ensure data is linear for pointer access

    const int anchors = output.size(0);
    const int channels = output.size(1);
    const float *data_ptr = output.data_ptr<float>();

    std::vector<cv::Rect> bboxes;
    std::vector<float> confs;

    for (int i = 0; i < anchors; ++i) {
        const float *row = data_ptr + (i * channels);

        float score = 0.0f;
        if (channels > 4) {
            // For YOLOv8/v10, indices 4 to end are class scores
            for (int j = 4; j < channels; ++j) {
                if (row[j] > score) score = row[j];
            }
        }

        if (score > 0.45f) {
            float cx = row[0], cy = row[1], w = row[2], h = row[3];
            int left = static_cast<int>(cx - w / 2.0f);
            int top = static_cast<int>(cy - h / 2.0f);
            bboxes.push_back(cv::Rect(left, top, static_cast<int>(w), static_cast<int>(h)));
            confs.push_back(score);
        }
    }

    if (bboxes.empty()) return {};

    // 5. NMS (OpenCV side)
    std::vector<int> indices;
    cv::dnn::NMSBoxes(bboxes, confs, 0.45f, 0.5f, indices);

    // 6. Final Scaling
    std::vector<DetectionBox> results;
    float scale_x = (float) frame.cols / 640.0f;
    float scale_y = (float) frame.rows / 640.0f;

    for (int idx: indices) {
        DetectionBox det;
        det.bbox.x = static_cast<int>(bboxes[idx].x * scale_x);
        det.bbox.y = static_cast<int>(bboxes[idx].y * scale_y);
        det.bbox.width = static_cast<int>(bboxes[idx].width * scale_x);
        det.bbox.height = static_cast<int>(bboxes[idx].height * scale_y);
        det.score = confs[idx];
        results.push_back(det);
    }
    return results;
}
```

```cpp
/**
 * src/tracker.cpp
 * @version 1.0 2026-01-03
 * @author cacc
 */
#include "tracker.h"

SharedTrack::SharedTrack(DetectionBox detection_box, int id) {
    track_id = id;
    score = detection_box.score;
    bbox = detection_box.bbox;
    frames_since_update = 0;

    kalman.init(4, 4, 0);
    kalman.transitionMatrix = (cv::Mat_<float>(4, 4) << 1,0,0,0, 0,1,0,0, 0,0,1,0, 0,0,0,1);
    setIdentity(kalman.measurementMatrix);
    setIdentity(kalman.processNoiseCov, cv::Scalar::all(1e-2));
    setIdentity(kalman.measurementNoiseCov, cv::Scalar::all(1e-2));
    setIdentity(kalman.errorCovPost, cv::Scalar::all(1));

    kalman.statePost = (cv::Mat_<float>(4, 1) << (float)bbox.x, (float)bbox.y, (float)bbox.width, (float)bbox.height);
}

void SharedTrack::predict() {
    cv::Mat prediction = kalman.predict();
    bbox.x = static_cast<int>(prediction.at<float>(0));
    bbox.y = static_cast<int>(prediction.at<float>(1));
    bbox.width = static_cast<int>(prediction.at<float>(2));
    bbox.height = static_cast<int>(prediction.at<float>(3));
    frames_since_update++;
}

void SharedTrack::update(DetectionBox detection_box) {
    cv::Mat measurement = (cv::Mat_<float>(4, 1) <<
        (float)detection_box.bbox.x,
        (float)detection_box.bbox.y,
        (float)detection_box.bbox.width,
        (float)detection_box.bbox.height);
    kalman.correct(measurement);
    bbox = detection_box.bbox;
    score = detection_box.score;
    frames_since_update = 0;
}

SortTracker::SortTracker(int max_age, float iou_threshold)
    : max_age(max_age), iou_threshold(iou_threshold) {}

double SortTracker::get_iou(cv::Rect rect1, cv::Rect rect2) {
    int interArea = (rect1 & rect2).area();
    int unionArea = rect1.area() + rect2.area() - interArea;
    if (unionArea <= 0) return 0;
    return static_cast<double>(interArea) / unionArea;
}

std::vector<SharedTrack> SortTracker::update(const std::vector<DetectionBox>& detections) {
    for (auto& track : tracks) {
        track.predict();
    }

    std::vector<bool> det_used(detections.size(), false);
    std::vector<bool> track_updated(tracks.size(), false);

    for (size_t i = 0; i < tracks.size(); ++i) {
        double best_iou = -1.0;
        int best_det_idx = -1;

        for (size_t j = 0; j < detections.size(); ++j) {
            if (det_used[j]) continue;

            double iou = get_iou(tracks[i].bbox, detections[j].bbox);
            if (iou > iou_threshold && iou > best_iou) {
                best_iou = iou;
                best_det_idx = static_cast<int>(j);
            }
        }

        if (best_det_idx != -1) {
            tracks[i].update(detections[best_det_idx]);
            det_used[best_det_idx] = true;
            track_updated[i] = true;
        }
    }

    for (size_t i = 0; i < detections.size(); ++i) {
        if (!det_used[i] && detections[i].score > 0.5) {
            tracks.emplace_back(detections[i], next_id++);
        }
    }

    tracks.erase(std::remove_if(tracks.begin(), tracks.end(),
        [this](const SharedTrack& t) {
            return t.frames_since_update > max_age;
        }), tracks.end());

    return tracks;
}
```

```cpp
/**
 * main.cpp
 * The entry of the program
 * @version 1.0 2026-01-03
 * @author cacc
 */
#include "detector.h"
#include "tracker.h"

const std::string MODEL_PATH = "/home/cacc/Workspace/FaceTracking/model/best.torchscript";
const int MAX_AGE = 15;
const float IOU_THRESHOLD = 0.3;

int main() {
    Detector detector(MODEL_PATH);
    SortTracker tracker(MAX_AGE, IOU_THRESHOLD);

    cv::VideoCapture cap(0);
    if (!cap.isOpened()) {
        std::cerr << "Camera Error!" << std::endl;
        return -1;
    }

    cv::Mat frame;
    while (cap.read(frame)) {
        auto detections = detector.inference(frame);

        auto online_tracks = tracker.update(detections);

        for (const auto& track : online_tracks) {
            cv::rectangle(frame, track.bbox, cv::Scalar(0, 255, 0), 2);
            std::string text = "ID: " + std::to_string(track.track_id);
            cv::putText(frame, text, cv::Point(track.bbox.x, track.bbox.y - 5),
                        cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(0, 255, 255), 2);
        }

        cv::imshow("Face Tracking", frame);
        if (cv::waitKey(1) == 27) break;
    }

    return 0;
}
```