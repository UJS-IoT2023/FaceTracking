项目地址：

https://github.com/UJS-IoT2023/FaceTracking

## 环境准备

首先我使用 uv 作为 Python 项目虚拟环境的管理，主要的第三方库设计 PyTorch 和 Ultratics。部署端使用 C++ 语言，利用 OpenCV 与 LibTorch 库进行模型部署。

C++ 的详细环境如下：


### C++ 环境准备

**LibTorch**

LibTorch 是适用于 C++/Java 的 Torch 运行库。

在 https://pytorch.org/ 网站下，有一个下载配置矩阵，首先查看本系统的环境信息：

```bash
nvidia-smi
```

获得如下输出

```
Fri Jan  2 21:16:23 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0  On |                  N/A |
| N/A   44C    P8              3W /   60W |      44MiB /   8188MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A      2350      G   /usr/lib/xorg/Xorg                             24MiB |
+-----------------------------------------------------------------------------------------+
```

代表显卡为 RTX4060，支持 CUDA 版本为 12.4

下载 Windows 系统 CUDA 12.4 的 LibTorch，使用 debug 版本：

在 `https://download.pytorch.org/libtorch/cu124/` 下找到 `libtorch-cxx11-abi-shared-with-deps-2.5.1%2Bcu124.zip` 这个文件

```bash
wget -c https://download.pytorch.org/libtorch/cu124/libtorch-cxx11-abi-shared-with-deps-2.5.1%2Bcu124.zip
```

**CUDA Toolkit**

需要找一个对应的 CUDA Toolkit 12.4，

```bash
wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda_12.4.1_550.54.15_linux.run
sudo sh cuda_12.4.1_550.54.15_linux.run
```

完成之后，这个工具包可能没有自动加入到环境变量，需要手动添加进环境变量

```bash
ls -l /usr/local/cuda-12.4/bin/nvcc  # Check the installation
```

```bash
# Append the path to the zshrc file
echo 'export PATH=/usr/local/cuda-12.4/bin${PATH:+:${PATH}}' >> ~/.zshrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.zshrc
echo 'export CUDA_HOME=/usr/local/cuda-12.4' >> ~/.zshrc

source ~/.zshrc
```

最后测试安装是否成功：

```bash
nvcc -V
```

```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Thu_Mar_28_02:18:24_PDT_2024
Cuda compilation tools, release 12.4, V12.4.131
Build cuda_12.4.r12.4/compiler.34097967_0
```

**OpenCV**

```bash
sudo apt update
sudo apt install libopencv-dev g++ cmake
```

### Python 环境准备

我使用 uv 进行包管理，相对于传统的 pip 和 venv，或者 conda，uv 提供了更加便捷的虚拟环境管理。下面通过 uv 添加所有需要的库。

```bash
uv add numpy pillow torch torchvision ultralytics
```

同样的，在克隆仓库时可以直接对项目的第三方依赖进行同步

```bash
uv sync
```

## 模型训练

在这里我们使用 YOLOv8n 模型作为基础模型，使用迁移学习的手段将一个预训练的 YOLOv8n 模型在准备的[人脸数据集](https://www.kaggle.com/datasets/fareselmenshawii/face-detection-dataset)上进行训练。随后通过 PyTorch 将训练好的模型转换为 torchscript 文件，便于 C++ 部署时通过 LibTorch 进行使用。

### 算法解释

在目标检测算法中，最先出现了 RCNN 等二阶段检测算法，这种算法由于分别检测导致了运算复杂。而 [YOLO（You Only Look Once）](https://ieeexplore.ieee.org/document/7780460) 作为单阶段目标检测的重要算法，首次在 2014 年被提出，它直接将待检测物体在图片中的位置回归出来，使得计算速度非常快。

![yolo](assets/yolo-structure.png)
<center>YOLO 初代结构</center>

模型接受的输入大小是 $448 \times 448 \times 3$，输出为 $7 \times 7 \times 30$，中间经过了卷积与池化。最后化为 $7 \times 7 \times 30$ 的张量，也就是最终提取出来的最终特征。其中最终的向量被看作 $S \times S \times (5 \times B + C)$，$S \times S$ 为图像被分割的区域数，$5 \times B$ 为锚框特征，在这里有 49 个锚框。分别为坐标，边框长宽与有物体的信心。

$$
\underbrace{(x, y, w, h, \text{objectness})}_{\text{5个参数}} \times B = 5B
$$

损失函数：

$$
\begin{equation}
\begin{split}
\mathcal{L} &= \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right] \\
&+ \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right] \\
&+ \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2 \\
&+ \lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2 \\
&+ \sum_{i=0}^{S^2} \mathbb{1}_{i}^{\text{obj}} \sum_{c \in \text{classes}} (p_i(c) - \hat{p}_i(c))^2
\end{split}
\end{equation}
$$

可以明显看出，YOLOv1的损失函数可以分为五个分项：

1. 预测框中心坐标与真实框的均方误差（MSE）
2. 对宽度 $w_i$ 和高度 $h_i$ 取平方根后的 MSE
3. 有目标的边界框的置信度与真实值的 MSE
4. 无目标的边框的置信度与真实值的 MSE
5. 每个网络的类别概率与真实类别

![nms](assets/yolo-nms.png)

提取到子区域的特征后，利用非极大值抑制（Non-Maximum Suppression，NMS）算法对所有候选边界框进行筛选。NMS通过比较每个预测框的置信度分数，保留置信度较高的框，并剔除与之高度重叠的低置信度

## 部署

根据上述环境安装好后，通过 `CMakeLists.txt` 对项目进行链接与定义

```cmake
cmake_minimum_required(VERSION 3.20)
project(deploy LANGUAGES CXX)

set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

set(CMAKE_CUDA_ARCHITECTURES 89)

set(CMAKE_CUDA_COMPILER /usr/local/cuda-12.4/bin/nvcc)

set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -allow-unsupported-compiler")

enable_language(CUDA)

set(CMAKE_PREFIX_PATH "/home/cacc/lib/libtorch")

find_package(OpenCV REQUIRED)
find_package(Torch REQUIRED)

add_executable(deploy main.cpp)

target_link_libraries(deploy PRIVATE ${TORCH_LIBRARIES} ${OpenCV_LIBS})
```

测试运行时，程序出现了错误

```
Forward Error: Error in dlopen for library libnvrtc.so.12and libnvrtc-XXXXXXXX.so.12

Exception raised from DynamicLibrary at ../aten/src/ATen/DynamicLibrary.cpp:33 (most recent call first):
```

由于是没有找到 so 文件，手动将这个文件的路径添加到环境变量中，通过 Clion 编辑器测试运行的 Edit Configuration 处，添加环境变量 `LD_LIBRARY_PATH` 为 `/home/cacc/lib/libtorch/lib:/usr/local/cuda-12.4/lib64`。

随后编译运行成功，程序如预期通过 OpenCV 调用摄像头，传递给 Torch 进行推理并通过 OpenCV 的 API 展示出一个简单的 GUI 画面，显示了实时检测人脸的程序。